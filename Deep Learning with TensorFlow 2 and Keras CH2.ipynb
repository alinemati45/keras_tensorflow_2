{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "angry-pitch",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Understanding-TensorFlow-2.x\" data-toc-modified-id=\"Understanding-TensorFlow-2.x-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Understanding TensorFlow 2.x</a></span><ul class=\"toc-item\"><li><span><a href=\"#eager-execution,\" data-toc-modified-id=\"eager-execution,-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>eager execution,</a></span></li></ul></li><li><span><a href=\"#Keras-APIs-–-three-programming-models\" data-toc-modified-id=\"Keras-APIs-–-three-programming-models-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Keras APIs – three programming models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sequential-API\" data-toc-modified-id=\"Sequential-API-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Sequential API</a></span></li><li><span><a href=\"#Functional-API\" data-toc-modified-id=\"Functional-API-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Functional API</a></span></li><li><span><a href=\"#Model-subclassing\" data-toc-modified-id=\"Model-subclassing-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Model subclassing</a></span></li></ul></li><li><span><a href=\"#Converting-from-1.x-to-2.x\" data-toc-modified-id=\"Converting-from-1.x-to-2.x-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Converting from 1.x to 2.x</a></span></li><li><span><a href=\"#Using-TensorFlow-2.x-effectively\" data-toc-modified-id=\"Using-TensorFlow-2.x-effectively-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Using TensorFlow 2.x effectively</a></span></li><li><span><a href=\"#Callbacks\" data-toc-modified-id=\"Callbacks-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Callbacks</a></span></li><li><span><a href=\"#Saving-a-model-and-weights\" data-toc-modified-id=\"Saving-a-model-and-weights-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Saving a model and weights</a></span></li><li><span><a href=\"#tf.keras-or-Estimators?\" data-toc-modified-id=\"tf.keras-or-Estimators?-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>tf.keras or Estimators?</a></span></li><li><span><a href=\"#Ragged-tensors\" data-toc-modified-id=\"Ragged-tensors-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Ragged tensors</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-richmond",
   "metadata": {},
   "source": [
    "# Understanding TensorFlow 2.x\n",
    "## eager execution,\n",
    "meaning that the model definitions are dynamic, and the execution is immediate.\n",
    "Graphs and sessions should be considered as implementation details. The good news is that TensorFlow 2.x natively supports \"eager execution.\"\n",
    "There is no longer the need to first statically define a computational graph and\n",
    "then execute it (unless you really wanted to!). All the models can be dynamically\n",
    "defined and immediately executed. \n",
    "\n",
    "AutoGraph comes into play: AutoGraph takes eager-style Python code\n",
    "and automatically converts it to graph-generating code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-finger",
   "metadata": {},
   "source": [
    "# Keras APIs – three programming models\n",
    "## Sequential API\n",
    "\n",
    "Sequential API when we discussed the MNIST code.\n",
    "\n",
    "## Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sufficient-corpus",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T16:34:25.335463Z",
     "start_time": "2021-09-30T16:34:22.443325Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils import plot_model\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    # variable-length sequence of integers\n",
    "    text_input_a = tf.keras.Input(shape=(None, ), dtype='int32')\n",
    "    # variable-length sequence of integers\n",
    "    text_input_b = tf.keras.Input(shape=(None, ), dtype='int32')\n",
    "    # Embedding for 1000 unique words mapped to 128-dimensional vectors\n",
    "    shared_embedding = tf.keras.layers.Embedding(1000, 128)\n",
    "    # We reuse the same layer to encode both inputs\n",
    "    encoded_input_a = shared_embedding(text_input_a)\n",
    "    encoded_input_b = shared_embedding(text_input_b)\n",
    "    # two logistic predictions at the end\n",
    "    prediction_a = tf.keras.layers.Dense(1,\n",
    "                                         activation='sigmoid',\n",
    "                                         name='prediction_a')(encoded_input_a)\n",
    "    prediction_b = tf.keras.layers.Dense(1,\n",
    "                                         activation='sigmoid',\n",
    "                                         name='prediction_b')(encoded_input_b)\n",
    "    # this model has 2 inputs, and 2 outputs\n",
    "    # in the middle we have a shared model\n",
    "    model = tf.keras.Model(inputs=[text_input_a, text_input_b],\n",
    "                           outputs=[prediction_a, prediction_b])\n",
    "#     tf.keras.utils.plot_model(model, to_file=\"./shared_model.png\")\n",
    "\n",
    "\n",
    "build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-pilot",
   "metadata": {},
   "source": [
    "<img src=\"./i/shared_model.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-royal",
   "metadata": {},
   "source": [
    "## Model subclassing\n",
    "\n",
    "Model subclassing offers the highest flexibility and it is generally used when\n",
    "you need to define your own layer. In other words, it is useful when you are in\n",
    "the business of building your own special lego brick instead of composing more\n",
    "standard and well-known bricks.\n",
    "\n",
    "    • __init__: Optionally used to define all the sublayers to be used by this layer.\n",
    "    This is the constructor where you can declare your model.\n",
    "    • build: Used to create the weights of the layer. You can add weights with\n",
    "    add_weight().\n",
    "    • call: Used to define the forward pass. This is where your layer is called and\n",
    "    chained in functional style.\n",
    "    • Optionally, a layer can be serialized by using get_config() and deserialized\n",
    "    using from_config()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "planned-crazy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T16:35:25.192311Z",
     "start_time": "2021-09-30T16:35:25.184708Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyLayer(layers.Layer):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "        shape=(input_shape[1], self.output_dim),\n",
    "        initializer='uniform',\n",
    "        trainable=True)\n",
    "    def call(self, inputs):\n",
    "    # Do the multiplication and return\n",
    "        return tf.matmul(inputs, self.kernel)\n",
    "    \n",
    "    \n",
    "model = tf.keras.Sequential([\n",
    "            MyLayer(20),\n",
    "            layers.Activation('softmax')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-alert",
   "metadata": {},
   "source": [
    "# Converting from 1.x to 2.x\n",
    "TensorFlow 1.x scripts will not work directly with TensorFlow 2.x but they need\n",
    "converting. The first step to convert from 1.x to 2.x is to use the automatic conversion\n",
    "script installed with 2.x. For a single file, you can run it with:\n",
    "\n",
    "tf_upgrade_v2 --infile tensorfoo.py --outfile tensorfoo-upgraded.py\n",
    "\n",
    "For multiple files in a directory, the syntax is:\n",
    "\n",
    "tf_upgrade_v2 --intree incode --outtree code-upgraded\n",
    "\n",
    "The script will try to upgrade automatically to 2.x and will print error messages\n",
    "where it is not able to upgrade.\n",
    "\n",
    "# Using TensorFlow 2.x effectively\n",
    "2.x native code should follow a number of best practices:\n",
    "\n",
    "    1. Default to higher-level APIs such as tf.keras (or in certain situations,\n",
    "    Estimators) and avoid lower-level APIs with direct computational graph\n",
    "    manipulation unless needed for custom operations. So, in general, no\n",
    "    tf.Session, tf.Session.run.\n",
    "    \n",
    "    2. Add a tf.function decorator to make it run efficiently in graph mode with\n",
    "    AutoGraph. Only use tf.function to decorate high-level computations; all\n",
    "    functions invoked by high-level computations are automatically annotated\n",
    "    on your behalf. In this way, you get the best of both worlds: high-level APIs\n",
    "    with eager support, and the efficiency of computational graphs.\n",
    "    \n",
    "    3. Use Python objects to track variables and losses. So, be Pythonic and use\n",
    "    tf.Variable instead of tf.get_variable. In this way, variables will be\n",
    "    treated with the normal Python scope.\n",
    "    \n",
    "    4. Use tf.data datasets for data inputs and provide these objects directly\n",
    "    to tf.keras.Model.fit. In this way, you will have a collection of highperformance classes for manipulating data and will adopt the best way to\n",
    "    stream training data from disk.\n",
    "    \n",
    "    5. Use tf.layers modules to combine predefined \"lego bricks\" whenever it\n",
    "    is possible, either with Sequential or Functional APIs, or with Subclassing.\n",
    "    Use Estimators if you need to have production-ready models, in particular\n",
    "    if these models need to scale on multiple GPUs, CPUs, or on multiple servers.\n",
    "    When needed, consider converting a tf.keras model into an Estimator.\n",
    "    \n",
    "    6. Consider using a distribution strategy across GPUs, CPUs, and multiple\n",
    "    servers. With tf.keras it is easy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-daisy",
   "metadata": {},
   "source": [
    "# Callbacks\n",
    "\n",
    "Callbacks are objects passed to a model to extend or modify behaviors during\n",
    "training. There are a few useful callbacks that are commonly used in tf.keras:\n",
    "1.  **tf.keras.callbacks.ModelCheckpoint**: This feature is used to save checkpoints of your model at regular intervals and recover in case of problems.\n",
    "\n",
    "2. **tf.keras.callbacks.LearningRateScheduler**: This feature is used to dynamically change the learning rate during optimization.\n",
    "3. **tf.keras.callbacks.EarlyStopping**: This feature is used to interrupt training when validation performance has stopped improving after a while.\n",
    "4. **tf.keras.callbacks.TensorBoard**: This feature is used to monitor the model's behavior using TensorBoard\n",
    "\n",
    "# Saving a model and weights\n",
    "After training a model, it can be useful to save the weights in a persistent way. This\n",
    "is easily achieved with the following code fragment, which saves to TensorFlow's\n",
    "internal format:\n",
    "\n",
    "```python\n",
    "# Save weights to a Tensorflow Checkpoint file\n",
    "model.save_weights('./weights/my_model')\n",
    "\n",
    "# Save weights to a HDF5 file\n",
    "model.save_weights('my_model.h5', save_format='h5')\n",
    "\n",
    "\n",
    "# Save weights to a Tensorflow Checkpoint file\n",
    "model.save_weights('./weights/my_model')\n",
    "\n",
    "# Save weights to a HDF5 file\n",
    "model.save_weights('my_model.h5', save_format='h5')\n",
    "\n",
    "# Save weights to a Tensorflow Checkpoint file\n",
    "model.save_weights('./weights/my_model')\n",
    "\n",
    "# Save weights to a HDF5 file\n",
    "model.save_weights('my_model.h5', save_format='h5')\n",
    "\n",
    "```\n",
    "\n",
    "# Training from tf.data.datasets\n",
    "Another benefit of using TensorFlow 2.x is the introduction of TensorFlow datasets\n",
    "as a principled mechanism to deal with heterogeneous (large) datasets in different\n",
    "categories such as audio, image, video, text, and translation. Let's first use pip to\n",
    "install tensorflow-datasets:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "disabled-causing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T16:50:43.561627Z",
     "start_time": "2021-09-30T16:50:43.545627Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install tensorflow-datasets\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "# See all registered datasets\n",
    "builders = tfds.list_builders()\n",
    "print(builders)\n",
    "# Load a given dataset by name, along with the DatasetInfo metadata\n",
    "data, info = tfds.load(\"mnist\", with_info=True)\n",
    "train_data, test_data = data['train'], data['test']\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-draft",
   "metadata": {},
   "source": [
    "# tf.keras or Estimators?\n",
    "In addition to the direct graph computation and to the tf.keras higher-level APIs,\n",
    "TensorFlow 1.x and 2.x have an additional set of higher-level APIs called Estimators.\n",
    "With Estimators, you do not need to worry about creating computational graphs or\n",
    "handling sessions, since Estimators deal with this on your behalf, in a similar way\n",
    "to tf.keras.\n",
    "\n",
    "But what are Estimators? Put simply, they are another way to build or to use prebuilt\n",
    "bricks. A longer answer is that they are highly efficient learning models for largescale production-ready environments, which can be trained on single machines\n",
    "or on distributed multi-servers, and they can run on CPUs, GPUs, or TPUs without\n",
    "recoding your model. These models include Linear Classifiers, Deep Learning\n",
    "Classifiers, Gradient Boosted Trees, and many more, which will be discussed in\n",
    "the upcoming chapters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "alert-turkish",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T16:49:57.390145Z",
     "start_time": "2021-09-30T16:48:55.403915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Single-worker CollectiveAllReduceStrategy with local_devices = ('/device:GPU:0',), communication = CollectiveCommunication.AUTO\n",
      "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/multiworker', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.python.distribute.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x000001C2E899AA48>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001C2E899AEC8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:The `input_fn` accepts an `input_context` which will be given by DistributionStrategy\n",
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\nemat\\tensorflow_datasets\\mnist\\3.0.1...\u001b[0m\n",
      "\u001b[1mDataset mnist downloaded and prepared to C:\\Users\\nemat\\tensorflow_datasets\\mnist\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n",
      "WARNING:tensorflow:From C:\\Users\\nemat\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nemat\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/multiworker\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/multiworker\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.3064291, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.3064291, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 155.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 155.759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.288177, step = 100 (0.643 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.288177, step = 100 (0.643 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 313.478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 313.478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.2941022, step = 200 (0.319 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.2941022, step = 200 (0.319 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 309.599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 309.599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.2867157, step = 300 (0.323 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.2867157, step = 300 (0.323 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 308.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 308.641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.287331, step = 400 (0.325 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.287331, step = 400 (0.325 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 296.736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 296.736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.277947, step = 500 (0.336 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.277947, step = 500 (0.336 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 289.855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 289.855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.299162, step = 600 (0.346 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.299162, step = 600 (0.346 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 287.356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 287.356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.2868636, step = 700 (0.347 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.2868636, step = 700 (0.347 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 324.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 324.675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.300441, step = 800 (0.309 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.300441, step = 800 (0.309 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 763.354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 763.354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.2791195, step = 900 (0.130 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.2791195, step = 900 (0.130 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 938 into /tmp/multiworker\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 938 into /tmp/multiworker\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2021-09-30T11:49:56Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2021-09-30T11:49:56Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/multiworker\\model.ckpt-938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/multiworker\\model.ckpt-938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2021-09-30-11:49:56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2021-09-30-11:49:56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 938: global_step = 938, loss = 2.2746527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 938: global_step = 938, loss = 2.2746527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 938: /tmp/multiworker\\model.ckpt-938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 938: /tmp/multiworker\\model.ckpt-938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 1.1391464.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 1.1391464.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'loss': 2.2746527, 'global_step': 938}, [])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "import os, json\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def input_fn(mode, input_context=None):\n",
    "  datasets, info = tfds.load(name='mnist',\n",
    "                                with_info=True,\n",
    "                                as_supervised=True)\n",
    "  mnist_dataset = (datasets['train'] if mode == tf.estimator.ModeKeys.TRAIN else\n",
    "                   datasets['test'])\n",
    "\n",
    "  def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    return image, label\n",
    "\n",
    "  if input_context:\n",
    "    mnist_dataset = mnist_dataset.shard(input_context.num_input_pipelines,\n",
    "                                        input_context.input_pipeline_id)\n",
    "  return mnist_dataset.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "def model_fn(features, labels, mode):\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(64, activation='relu'),\n",
    "      tf.keras.layers.Dense(10)\n",
    "  ])\n",
    "  logits = model(features, training=False)\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    predictions = {'logits': logits}\n",
    "    return tf.estimator.EstimatorSpec(labels=labels, predictions=predictions)\n",
    "\n",
    "  optimizer = tf.compat.v1.train.GradientDescentOptimizer(\n",
    "      learning_rate=LEARNING_RATE)\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(labels, logits)\n",
    "  loss = tf.reduce_sum(loss) * (1. / BATCH_SIZE)\n",
    "  if mode == tf.estimator.ModeKeys.EVAL:\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss)\n",
    "\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      loss=loss,\n",
    "      train_op=optimizer.minimize(\n",
    "          loss, tf.compat.v1.train.get_or_create_global_step()))\n",
    "\n",
    "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "\n",
    "config = tf.estimator.RunConfig(train_distribute=strategy)\n",
    "\n",
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=model_fn, model_dir='/tmp/multiworker', config=config)\n",
    "tf.estimator.train_and_evaluate(\n",
    "    classifier,\n",
    "    train_spec=tf.estimator.TrainSpec(input_fn=input_fn),\n",
    "    eval_spec=tf.estimator.EvalSpec(input_fn=input_fn)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-decade",
   "metadata": {},
   "source": [
    "# Ragged tensors\n",
    "Continuing our discussion on the benefits of TensorFlow 2.x, we should notice that\n",
    "TensorFlow 2.x added support for \"ragged\" tensors, which are a special type of dense\n",
    "tensor with non-uniformly shaped dimensions. This is particularly useful for dealing\n",
    "with sequences and other data issues where the dimensions can change across\n",
    "batches, such as text sentences and hierarchical data. Note that ragged tensors are\n",
    "more efficient than padding tf.Tensor, since no time or space is wasted:\n",
    "ragged = tf.ragged.constant([[1, 2, 3], [3, 4], [5, 6, 7, 8]]) ==>\n",
    "<tf.RaggedTensor [[1, 2, 3], [3, 4], [5, 6, 7, 8]]>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-bailey",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
